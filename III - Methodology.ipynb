{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "\n",
    "pd.set_option('display.max_columns', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./flights_clean.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the jupyter notebook titled II - Analysis to know how the data was preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the trained models it is necessary to prepare the data for training and testing, it will be used a split for test and train, then a dummy classifier will be trained and tested to have a benchmark to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[df['WEEK'] < 10]\n",
    "df_sample.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing the data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sample.drop(columns=[\"LABELS\"])\n",
    "y = df_sample.drop(columns=[\"DAY_OF_WEEK\", \"AIRLINE\", \"FLIGHT_NUMBER\", \"TAIL_NUMBER\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\", \"SCHEDULED_DEPARTURE\", \"SCHEDULED_TIME\", \"DISTANCE\", \"SCHEDULED_ARRIVAL\", \"WEEK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training a Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"The training dataset contains {} datapoints, while the testing dataset contains {} datapoints.\".format(X_train.shape[0], X_test.shape[0])\n",
    "print \"The training dataset contains {} labels, while the testing dataset contains {} labels.\".format(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"F1 score for set: {:.4f}\".format(f1_score(y_test, y_pred_dummy, pos_label=\"NOT DELAYED\"))\n",
    "print \"Kappa score for set {:.4f}\".format(cohen_kappa_score(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    print \"F1 score for set: {:.4f}.\".format(f1_score(target.values, y_pred, pos_label=\"NOT DELAYED\"))\n",
    "    print \"Kappa score for set: {:.4f}\".format(cohen_kappa_score(target.values, y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"====== Training Set ======\"\n",
    "    predict_labels(clf, X_train, y_train)\n",
    "    print \"====== Testing Set ======\"\n",
    "    predict_labels(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "clf_dt = DecisionTreeClassifier(random_state=3)\n",
    "clf_rf = RandomForestClassifier(random_state=3)\n",
    "\n",
    "# Set up the training set sizes\n",
    "X_train_10k = X_train[:10000]\n",
    "y_train_10k = y_train[:10000]\n",
    "\n",
    "X_train_20k = X_train[:20000]\n",
    "y_train_20k = y_train[:20000]\n",
    "\n",
    "X_train_30k = X_train[:30000]\n",
    "y_train_30k = y_train[:30000]\n",
    "\n",
    "# First classifier: Decision Tree\n",
    "train_predict(clf_dt, X_train_10k, y_train_10k, X_test, y_test)\n",
    "train_predict(clf_dt, X_train_20k, y_train_20k, X_test, y_test)\n",
    "train_predict(clf_dt, X_train_30k, y_train_30k, X_test, y_test)\n",
    "# Second classifier: Random Forest\n",
    "train_predict(clf_rf, X_train_10k, y_train_10k, X_test, y_test)\n",
    "train_predict(clf_rf, X_train_20k, y_train_20k, X_test, y_test)\n",
    "train_predict(clf_rf, X_train_30k, y_train_30k, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classifer 1 - Decision Tree**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) | Kappa Score (train) | Kappa Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: | :--------------: | :-------------: |\n",
    "| 10000               | 2.5820                  | 44.3490                 | 1.0000           | 0.6723      | 1.0000           | 0.1476      |\n",
    "| 20000               | 7.8360                  | 43.9529                 | 1.0000           | 0.6804      | 1.0000           | 0.1660      |\n",
    "| 30000               | 12.9322                 | 44.2589                 | 1.0000           | 0.6885      | 1.0000           | 0.1814      |\n",
    "\n",
    "** Classifer 2 - Random Forest**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) | Kappa Score (train) | Kappa Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: | :--------------: | :-------------: |\n",
    "| 10000               | 3.5879                  | 51.3358                | 0.9903           | 0.6988       | 0.9750           | 0.1887\n",
    "| 20000               | 8.2012                  | 49.9041                | 0.9908           | 0.6998       | 0.9766           | 0.2013\n",
    "| 30000               | 13.3635                 | 51.3536                | 0.9898           | 0.7007       | 0.9741           | 0.2114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_100k = X_train[:100000]\n",
    "y_train_100k = y_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict(clf_rf, X_train_100k, y_train_100k, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tunning the model to improve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scorer = make_scorer(cohen_kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {\n",
    "    'max_depth' : [10, 20, 50, 100, 300],\n",
    "    'n_estimators' : [10, 20, 50, 100, 300]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search on the classifier\n",
    "rsearch_rf = RandomizedSearchCV(clf_rf, rf_parameters, 2, kappa_scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "rsearch_rf = rsearch_rf.fit(X_train_30k, y_train_30k)\n",
    "\n",
    "# Get the estimator\n",
    "clf_rf = rsearch_rf.best_estimator_\n",
    "\n",
    "# Show the best parameters\n",
    "print rsearch_rf.best_params_\n",
    "print \"====== Training Set ======\"\n",
    "predict_labels(clf_rf, X_train_30k, y_train_30k)\n",
    "print \"====== Testing Set ======\"\n",
    "predict_labels(clf_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exporting a visualization for the first tree in the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf_rf.estimators_[0], out_file='example_tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(['dot', '-Tpng', 'example_tree.dot', '-o', 'example_tree.png', '-Gdpi=600'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tunning the not selected model to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parameters = {\n",
    "    'max_depth' : [10, 20, 50, 100, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search on the classifier\n",
    "rsearch_dt = RandomizedSearchCV(clf_dt, dt_parameters, 1, kappa_scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "rsearch_dt = rsearch_dt.fit(X_train_30k, y_train_30k)\n",
    "\n",
    "# Get the estimator\n",
    "clf_dt = rsearch_dt.best_estimator_\n",
    "\n",
    "# Show the best parameters\n",
    "print rsearch_dt.best_params_\n",
    "print \"====== Training Set ======\"\n",
    "predict_labels(clf_dt, X_train_30k, y_train_30k)\n",
    "print \"====== Testing Set ======\"\n",
    "predict_labels(clf_dt, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
